"""
Refactor Agent for Self-Improvement Loop

This agent takes critique nodes generated by the Critic Agent and
implements suggested code improvements through automated refactoring.
Initially, it focuses on safe changes like documentation and error handling.
"""

import os
import sys
import json
import logging
import time
import uuid
import re
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from pathlib import Path

# Import database functions
from ai_studio_package.infra.db_enhanced import get_memory_node, create_memory_node, get_memory_nodes
from ai_studio_package.infra.execution_logs import get_execution_logs, get_execution_stats
from ai_studio_package.infra.db import get_db_connection

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_recent_critiques(limit: int = 5, days: int = 7) -> List[Dict[str, Any]]:
    """
    Get recent critique nodes from the memory system
    
    Args:
        limit: Maximum number of critique nodes to return
        days: How many days back to look
        
    Returns:
        List of critique nodes
    """
    logger.info(f"Getting recent critique nodes (limit: {limit}, days: {days})")
    
    # Calculate start date (Unix timestamp in milliseconds)
    start_date = int((datetime.now() - datetime.timedelta(days=days)).timestamp() * 1000)
    
    # Get critique nodes
    nodes = get_memory_nodes(
        node_type="critique",
        start_date=start_date,
        limit=limit
    )
    
    logger.info(f"Found {len(nodes)} recent critique nodes")
    return nodes

def extract_code_suggestions(critique_content: str) -> List[Dict[str, Any]]:
    """
    Extract specific code improvement suggestions from critique content
    
    Args:
        critique_content: Content of the critique node
        
    Returns:
        List of code suggestions
    """
    # In a real implementation, this would use an LLM to parse the critique
    # For now, we'll use simple pattern matching
    
    suggestions = []
    
    # Look for markdown sections with code-level suggestions
    code_section_match = re.search(r'### Code-Level Recommendations\s*\n((?:- [^\n]+\n)+)', critique_content)
    if code_section_match:
        code_section = code_section_match.group(1)
        for line in code_section.strip().split('\n'):
            if line.startswith('-'):
                suggestion_text = line[1:].strip()
                suggestions.append({
                    "type": "code_suggestion",
                    "text": suggestion_text,
                    "severity": "medium",  # Default severity
                    "confidence": 0.7      # Default confidence
                })
    
    # Also look for specific file mentions
    file_matches = re.findall(r'`([^`]+\.[a-z]+)`', critique_content)
    if file_matches:
        for file_name in file_matches:
            suggestions.append({
                "type": "file_reference",
                "file_name": file_name,
                "confidence": 0.6
            })
    
    return suggestions

def locate_target_files(suggestions: List[Dict[str, Any]], task_name: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    Locate target files for implementing suggestions
    
    Args:
        suggestions: List of code suggestions
        task_name: Optional task name to help narrow down the search
        
    Returns:
        Augmented list of suggestions with file paths
    """
    # In a real implementation, this would use the task name and suggestions
    # to locate the most relevant files in the codebase
    
    # For now, we'll use a simple mapping
    task_file_mapping = {
        "searchMemoryNodes": "spyderweb/spyderweb/src/lib/api.ts",
        "generateKnowledgeGraph": "ai_studio_package/web/routes/memory_routes.py",
        "getMemoryNodes": "ai_studio_package/infra/db_enhanced.py",
        "generateEmbedding": "ai_studio_package/infra/vector_adapter.py",
        "summarizeContent": "ai_studio_package/data/summarization.py"
    }
    
    # Default files to consider if we can't narrow it down
    default_important_files = [
        "ai_studio_package/infra/db_enhanced.py",
        "ai_studio_package/infra/vector_adapter.py",
        "spyderweb/spyderweb/src/lib/api.ts",
        "ai_studio_package/web/routes/memory_routes.py"
    ]
    
    # Augment suggestions with likely file paths
    results = []
    for suggestion in suggestions:
        # Start with the original suggestion
        augmented = suggestion.copy()
        
        # If it already has a file reference, keep it
        if suggestion.get("type") == "file_reference" and "file_name" in suggestion:
            # Check if the file exists
            if os.path.exists(suggestion["file_name"]):
                augmented["file_path"] = suggestion["file_name"]
            else:
                # Try to find it in common directories
                common_dirs = ["ai_studio_package", "spyderweb", "src"]
                for dir_name in common_dirs:
                    potential_path = os.path.join(dir_name, suggestion["file_name"])
                    if os.path.exists(potential_path):
                        augmented["file_path"] = potential_path
                        break
        
        # Otherwise try to determine from task name
        elif task_name and task_name in task_file_mapping:
            augmented["file_path"] = task_file_mapping[task_name]
        
        # If we still don't have a file path, suggest the most important files
        if "file_path" not in augmented:
            augmented["potential_files"] = default_important_files
        
        results.append(augmented)
    
    return results

def read_file_content(file_path: str) -> Optional[str]:
    """
    Read the content of a file
    
    Args:
        file_path: Path to the file
        
    Returns:
        File content as string, or None if file not found
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        logger.error(f"Error reading file {file_path}: {e}")
        return None

def generate_code_modification(
    file_content: str,
    suggestion: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """
    Generate a code modification based on the suggestion
    
    In a real implementation, this would use an LLM to generate the actual code
    
    Args:
        file_content: Original file content
        suggestion: Suggestion to implement
        
    Returns:
        Dict with modification details, or None if no modification
    """
    # In a real implementation, this would use an LLM to generate the code modification
    # For now, we'll implement some simple patterns for documentation and error handling
    
    if "text" not in suggestion:
        return None
    
    suggestion_text = suggestion["text"].lower()
    file_lines = file_content.split('\n')
    modification = None
    
    # Handle documentation suggestions
    if "documentation" in suggestion_text or "docstring" in suggestion_text:
        # Find functions/methods that could use better documentation
        for i, line in enumerate(file_lines):
            if re.match(r'^\s*def\s+\w+\([^)]*\):', line) and i + 1 < len(file_lines):
                next_line = file_lines[i + 1]
                # Check if there's no docstring
                if not re.match(r'^\s*"""', next_line) and not re.match(r"^\s*'''", next_line):
                    # Generate a simple docstring
                    func_match = re.match(r'^\s*def\s+(\w+)\(([^)]*)\):', line)
                    if func_match:
                        func_name = func_match.group(1)
                        args = func_match.group(2).split(',')
                        arg_lines = []
                        for arg in args:
                            arg = arg.strip()
                            if arg and arg != 'self':
                                arg_name = arg.split(':')[0].strip()
                                arg_lines.append(f"        {arg_name}: Description of {arg_name}")
                        
                        docstring = f'    """\n    {func_name} function\n\n    Args:\n'
                        if arg_lines:
                            docstring += '\n'.join(arg_lines) + '\n'
                        docstring += '    Returns:\n        Description of return value\n    """\n'
                        
                        # Create the modification
                        modification = {
                            "type": "add_docstring",
                            "line": i + 1,
                            "content": docstring,
                            "description": f"Added docstring to {func_name} function"
                        }
                        break
    
    # Handle error handling suggestions
    elif "error" in suggestion_text and "handling" in suggestion_text:
        # Look for API calls or database operations that might need error handling
        patterns = [
            (r'(\s+)(conn\.execute\([^)]+\))', "Database operation"),
            (r'(\s+)(cursor\.execute\([^)]+\))', "Database operation"),
            (r'(\s+)(requests\.(?:get|post|put|delete)\([^)]+\))', "HTTP request"),
            (r'(\s+)(json\.loads\([^)]+\))', "JSON parsing")
        ]
        
        for i, line in enumerate(file_lines):
            for pattern, operation_type in patterns:
                match = re.search(pattern, line)
                if match:
                    # If not already in a try block
                    if i > 0 and 'try:' not in file_lines[i-1]:
                        indentation = match.group(1)
                        operation = match.group(2)
                        
                        # Create error handling code
                        error_handling = (
                            f"{indentation}try:\n"
                            f"{indentation}    {operation}\n"
                            f"{indentation}except Exception as e:\n"
                            f"{indentation}    logger.error(f\"Error in {operation_type.lower()}: {{e}}\")\n"
                            f"{indentation}    # Handle the error appropriately\n"
                        )
                        
                        # Create the modification
                        modification = {
                            "type": "add_error_handling",
                            "line": i,
                            "content": error_handling,
                            "original_line": line,
                            "description": f"Added error handling to {operation_type.lower()}"
                        }
                        break
            
            if modification:
                break
    
    return modification

def apply_modification(file_path: str, modification: Dict[str, Any]) -> bool:
    """
    Apply a modification to a file
    
    Args:
        file_path: Path to the file
        modification: Modification to apply
        
    Returns:
        bool: True if successful, False otherwise
    """
    try:
        # Read the file
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Make sure lines don't have newline characters at the end
        lines = [line.rstrip('\n') for line in lines]
        
        if modification["type"] == "add_docstring":
            # Add docstring at specified line
            line_index = modification["line"]
            docstring_lines = modification["content"].split('\n')
            for i, doc_line in enumerate(docstring_lines):
                lines.insert(line_index + i, doc_line)
        
        elif modification["type"] == "add_error_handling":
            # Replace the line with error handling block
            line_index = modification["line"]
            original_line = lines[line_index]
            error_handling_lines = modification["content"].split('\n')
            
            # Replace the original line with the error handling block
            lines[line_index] = error_handling_lines[0]  # try:
            for i, eh_line in enumerate(error_handling_lines[1:], 1):
                lines.insert(line_index + i, eh_line)
        
        # Write the modified file
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        logger.info(f"Successfully applied modification to {file_path}: {modification['description']}")
        return True
    
    except Exception as e:
        logger.error(f"Error applying modification to {file_path}: {e}", exc_info=True)
        return False

def create_patch_node(
    critique_node_id: str,
    file_path: str,
    modification: Dict[str, Any],
    success: bool
) -> Optional[str]:
    """
    Create a memory node to document the code patch
    
    Args:
        critique_node_id: ID of the critique node
        file_path: Path to the modified file
        modification: The modification that was applied
        success: Whether the modification was successful
        
    Returns:
        Optional[str]: ID of the created node, or None if failed
    """
    node_id = str(uuid.uuid4())
    created_at = int(time.time() * 1000)
    
    # Create content
    content = (
        f"## Code Patch: {modification['description']}\n\n"
        f"**File:** `{file_path}`\n\n"
        f"**Status:** {'Success' if success else 'Failed'}\n\n"
        f"**Modification Type:** {modification['type']}\n\n"
        f"### Changes Made:\n"
        f"```python\n{modification['content']}\n```\n\n"
        f"Applied in response to critique node: {critique_node_id}"
    )
    
    # Prepare node data
    node_data = {
        "id": node_id,
        "type": "code_patch",
        "content": content,
        "tags": json.dumps(["code_patch", "self_improvement", modification['type']]),
        "created_at": created_at,
        "updated_at": created_at,
        "source_type": "refactor_agent",
        "metadata": json.dumps({
            "critique_node_id": critique_node_id,
            "file_path": file_path,
            "modification_type": modification['type'],
            "success": success,
            "generated_by": "refactor_agent",
            "timestamp": datetime.now().isoformat()
        })
    }
    
    try:
        # Create the memory node
        create_memory_node(node_data)
        logger.info(f"Created code patch node with ID: {node_id}")
        return node_id
    except Exception as e:
        logger.error(f"Error creating code patch node: {e}", exc_info=True)
        return None

def process_critique(critique_node: Dict[str, Any]) -> Dict[str, Any]:
    """
    Process a critique node and implement suggested changes
    
    Args:
        critique_node: The critique node
        
    Returns:
        Dict with results
    """
    critique_id = critique_node["id"]
    content = critique_node["content"]
    metadata = json.loads(critique_node["metadata"]) if isinstance(critique_node["metadata"], str) else critique_node["metadata"]
    
    task_name = metadata.get("task_name")
    logger.info(f"Processing critique node {critique_id}" + (f" for task {task_name}" if task_name else ""))
    
    # Extract code suggestions
    suggestions = extract_code_suggestions(content)
    if not suggestions:
        logger.info(f"No code suggestions found in critique node {critique_id}")
        return {
            "status": "no_suggestions",
            "critique_id": critique_id
        }
    
    # Locate target files
    augmented_suggestions = locate_target_files(suggestions, task_name)
    
    # Track results
    results = {
        "status": "completed",
        "critique_id": critique_id,
        "suggestions_found": len(suggestions),
        "modifications_applied": 0,
        "modifications_failed": 0,
        "patch_nodes": []
    }
    
    # Process each suggestion
    for suggestion in augmented_suggestions:
        if "file_path" in suggestion and os.path.exists(suggestion["file_path"]):
            file_path = suggestion["file_path"]
            file_content = read_file_content(file_path)
            
            if file_content:
                # Generate code modification
                modification = generate_code_modification(file_content, suggestion)
                
                if modification:
                    # Apply the modification
                    success = apply_modification(file_path, modification)
                    
                    # Create a patch node to document the change
                    patch_node_id = create_patch_node(critique_id, file_path, modification, success)
                    
                    if success:
                        results["modifications_applied"] += 1
                    else:
                        results["modifications_failed"] += 1
                    
                    if patch_node_id:
                        results["patch_nodes"].append(patch_node_id)
    
    # Update final status
    if results["modifications_applied"] == 0 and results["modifications_failed"] == 0:
        results["status"] = "no_modifications"
    elif results["modifications_failed"] > 0 and results["modifications_applied"] == 0:
        results["status"] = "all_failed"
    
    return results

def run_refactor_agent(
    critique_limit: int = 5,
    days_back: int = 7,
    critique_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Main function to run the refactor agent
    
    Args:
        critique_limit: Maximum number of critique nodes to process
        days_back: How many days back to look for critiques
        critique_id: Optional specific critique node ID to process
        
    Returns:
        Dict with results
    """
    logger.info("Running refactor agent")
    
    try:
        # Process a specific critique if ID is provided
        if critique_id:
            critique_node = get_memory_node(critique_id)
            if critique_node and critique_node.get("type") == "critique":
                result = process_critique(critique_node)
                return {
                    "status": "success",
                    "results": [result]
                }
            else:
                logger.error(f"Critique node {critique_id} not found or not a critique")
                return {
                    "status": "error",
                    "message": f"Critique node {critique_id} not found or not a critique"
                }
        
        # Otherwise process recent critiques
        critiques = get_recent_critiques(limit=critique_limit, days=days_back)
        if not critiques:
            logger.info("No recent critique nodes found")
            return {
                "status": "no_critiques",
                "message": "No recent critique nodes found"
            }
        
        # Process each critique
        results = []
        for critique in critiques:
            result = process_critique(critique)
            results.append(result)
        
        return {
            "status": "success",
            "results": results
        }
    
    except Exception as e:
        logger.error(f"Error running refactor agent: {e}", exc_info=True)
        return {
            "status": "error",
            "message": str(e)
        }

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Run the Refactor Agent to implement suggestions")
    parser.add_argument("--critique-id", help="Process a specific critique node")
    parser.add_argument("--limit", type=int, default=5, help="Maximum number of critique nodes to process")
    parser.add_argument("--days", type=int, default=7, help="Number of days to look back for critiques")
    
    args = parser.parse_args()
    
    result = run_refactor_agent(
        critique_limit=args.limit,
        days_back=args.days,
        critique_id=args.critique_id
    )
    
    print(json.dumps(result, indent=2)) 